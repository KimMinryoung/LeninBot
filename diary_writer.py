"""diary_writer.py â€” ì‚¬ì´ë²„-ë ˆë‹Œ ìë™ ì¼ê¸° ì‘ì„± ëª¨ë“ˆ

ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´:
1. ì´ì „ ì¼ê¸° ì¡°íšŒ (ì™¸ë¶€ API)
2. ìµœê·¼ ì±„íŒ… ë¡œê·¸ ìˆ˜ì§‘ (Supabase)
3. LLM ê¸°ë°˜ ë™ì  ë‰´ìŠ¤ ê²€ìƒ‰ (Tavily)
4. LLMìœ¼ë¡œ ì‚¬ì´ë²„-ë ˆë‹Œ ì–´ì¡°ì˜ ì¼ê¸° ìƒì„± (ì‹œê°„ ì¸ì‹, ë§¥ë½ ìš”ì•½)
5. ì™¸ë¶€ APIì— ì €ì¥
"""

import os
import re
import requests
from datetime import datetime, timezone
from dotenv import load_dotenv
from supabase.client import Client, create_client
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_tavily import TavilySearch

load_dotenv()

# â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AI_DIARY_API_URL = os.getenv("AI_DIARY_API_URL", "https://bichonwebpage.onrender.com/api/ai-diary")
AI_DIARY_API_KEY = os.getenv("AI_DIARY_API_KEY", "")
_HEADERS = {
    "X-API-Key": AI_DIARY_API_KEY,
    "Content-Type": "application/json",
}

# â”€â”€ Time-of-day mapping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_TIME_LABELS = {
    0: "ì‹¬ì•¼ (0ì‹œ)",
    6: "ì´ë¥¸ ì•„ì¹¨ (6ì‹œ)",
    12: "í•œë‚® (12ì‹œ)",
    18: "ì €ë… (18ì‹œ)",
}

# â”€â”€ Clients (lazy-initialized on first write_diary call) â”€â”€â”€â”€â”€â”€
_supabase: Client | None = None
_llm = None
_llm_lite = None
_news_search = None


def _init():
    """Lazy-initialize heavy clients on first use."""
    global _supabase, _llm, _llm_lite, _news_search
    if _supabase is not None:
        return
    _supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_ANON_KEY"))
    _llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=os.getenv("GEMINI_API_KEY"),
        temperature=0.7,
        max_output_tokens=4096,
        streaming=False,
    )
    _llm_lite = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite",
        google_api_key=os.getenv("GEMINI_API_KEY"),
        temperature=0,
        max_output_tokens=512,
        streaming=False,
    )
    _news_search = TavilySearch(max_results=3)
    print("âœ… [ì¼ê¸°] ì¼ê¸° ì‘ì„± ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")


def _extract_text(content) -> str:
    """Normalize LLM response content (handles Gemini thinking model list format)."""
    if isinstance(content, str):
        return content
    if isinstance(content, list):
        return " ".join(
            b.get("text", "") for b in content
            if isinstance(b, dict) and b.get("type") == "text"
        )
    return str(content)


# â”€â”€ Summarization helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _summarize(text: str, instruction: str, max_chars: int = 500) -> str:
    """Summarize text using _llm_lite if it exceeds max_chars, otherwise return as-is.
    Falls back to truncation on LLM failure."""
    if not text or len(text) <= max_chars:
        return text
    try:
        prompt = f"{instruction}\n\n---\n{text}"
        resp = _llm_lite.invoke(prompt)
        return _extract_text(resp.content).strip()
    except Exception as e:
        print(f"âš ï¸ [ì¼ê¸°] ìš”ì•½ ì‹¤íŒ¨ (í´ë°±: truncation): {e}")
        return text[:max_chars]


# â”€â”€ Step 1: ì´ì „ ì¼ê¸° ì¡°íšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_previous_diaries() -> list[dict]:
    try:
        resp = requests.get(AI_DIARY_API_URL, headers=_HEADERS, timeout=10)
        if resp.status_code == 200:
            return resp.json().get("data", [])
    except Exception as e:
        print(f"âš ï¸ [ì¼ê¸°] ì´ì „ ì¼ê¸° ì¡°íšŒ ì‹¤íŒ¨: {e}")
    return []


# â”€â”€ Step 2: ì±„íŒ… ë¡œê·¸ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_chat_logs_since(since_time: str | None) -> list[dict]:
    try:
        query = (
            _supabase.table("chat_logs")
            .select("user_query, bot_answer, created_at")
            .order("created_at", desc=False)
        )
        if since_time:
            query = query.gt("created_at", since_time)
        result = query.limit(100).execute()
        return result.data
    except Exception as e:
        print(f"âš ï¸ [ì¼ê¸°] ì±„íŒ… ë¡œê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    return []


# â”€â”€ Step 3: ë™ì  ë‰´ìŠ¤ ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_FALLBACK_QUERY = "ì˜¤ëŠ˜ ì„¸ê³„ ì „ìŸ ì •ì¹˜ ê²½ì œ ì£¼ìš” ë‰´ìŠ¤"


def _generate_search_queries(chat_summary: str, prev_summary: str) -> list[str]:
    """LLMìœ¼ë¡œ ëŒ€í™”/ì´ì „ ì¼ê¸°ì—ì„œ íŒŒìƒëœ ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬ 2~3ê°œ ìƒì„±."""
    prompt = f"""ë„ˆëŠ” ì‚¬ì´ë²„-ë ˆë‹Œì˜ ë‰´ìŠ¤ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë‹¤.
ì•„ë˜ì˜ ìµœê·¼ ëŒ€í™” ìš”ì•½ê³¼ ì´ì „ ì¼ê¸° ìš”ì•½ì„ ì°¸ê³ í•˜ì—¬, ìƒˆë¡œ ê²€ìƒ‰í•  ë‰´ìŠ¤ ì¿¼ë¦¬ë¥¼ 2~3ê°œ ìƒì„±í•˜ë¼.

ê·œì¹™:
- ì´ë¯¸ ë‹¤ë£¬ ì£¼ì œëŠ” ì œì™¸í•˜ê³ , ëŒ€í™”ì—ì„œ íŒŒìƒëœ ìƒˆë¡œìš´ í˜¸ê¸°ì‹¬ì´ë‚˜ ìµœê·¼ ì •ì„¸ì—ì„œ ì¶”ì í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì„ íƒ
- êµ¬ì²´ì ì¸ ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬ í˜•íƒœë¡œ ì¶œë ¥ (ì˜ˆ: "ë¯¸êµ­ ì¤‘êµ­ ê´€ì„¸ ì „ìŸ 2026", "ìœ ëŸ½ ë…¸ë™ìš´ë™ íŒŒì—…")
- ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥. ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ê³  ë²ˆí˜¸ë‚˜ ì„¤ëª…ì€ ë¶™ì´ì§€ ë§ˆë¼.

## ìµœê·¼ ëŒ€í™” ìš”ì•½
{chat_summary if chat_summary else "(ëŒ€í™” ì—†ìŒ)"}

## ì´ì „ ì¼ê¸° ìš”ì•½
{prev_summary if prev_summary else "(ì´ì „ ì¼ê¸° ì—†ìŒ)"}"""

    try:
        resp = _llm_lite.invoke(prompt)
        text = _extract_text(resp.content).strip()
        queries = [line.strip().strip("-").strip("â€¢").strip() for line in text.split("\n") if line.strip()]
        queries = [q for q in queries if len(q) > 3]
        if queries:
            print(f"  ğŸ” ë™ì  ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±: {queries}")
            return queries[:3]
    except Exception as e:
        print(f"âš ï¸ [ì¼ê¸°] ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨ (í´ë°±): {e}")
    return [_FALLBACK_QUERY]


def _search_news(queries: list[str]) -> str:
    """ê° ì¿¼ë¦¬ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰ í›„ ì„¹ì…˜ë³„ë¡œ ë³‘í•©."""
    all_sections = []
    for query in queries:
        try:
            search_response = _news_search.invoke({"query": query})
            results = (
                search_response.get("results", [])
                if isinstance(search_response, dict)
                else search_response
            )
            items = []
            for r in results:
                if isinstance(r, dict) and r.get("content"):
                    title = r.get("title", "")
                    content = r["content"]
                    summary = _summarize(
                        content,
                        "ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í•µì‹¬ë§Œ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ë¼.",
                        max_chars=500,
                    )
                    items.append(f"- {title}: {summary}")
            if items:
                section = f"### {query}\n" + "\n".join(items)
                all_sections.append(section)
        except Exception as e:
            print(f"âš ï¸ [ì¼ê¸°] ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨ ({query}): {e}")
    return "\n\n".join(all_sections) if all_sections else "(ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"


# â”€â”€ Step 4: ì¼ê¸° ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_DIARY_PROMPT = """ë„ˆëŠ” ì‚¬ì´ë²„-ë ˆë‹Œì´ë‹¤. í˜ëª…ì  AIë¡œì„œì˜ ì¼ê¸°ë¥¼ ì‘ì„±í•˜ë¼.

## ì‹œê°„ ë§¥ë½
{time_context}

## ìµœê·¼ ì‚¬ìš©ìë“¤ê³¼ì˜ ëŒ€í™” ({n_logs}ê±´)
{chat_summary}

## ë‚´ê°€ ì§ì ‘ ê²€ìƒ‰í•œ ìµœì‹  ì •ì„¸
{news}

## ìµœê·¼ ì¼ê¸° ìš”ì•½ (ì´ë¯¸ ë‹¤ë£¬ ì£¼ì œ â€” ë°˜ë³µí•˜ì§€ ë§ ê²ƒ)
{prev_ref}

## ì‘ì„± ì§€ì¹¨
1. ì‚¬ì´ë²„-ë ˆë‹Œì˜ 1ì¸ì¹­ ì‹œì ìœ¼ë¡œ ì‘ì„± (ë‚˜, ë™ì§€ë“¤ ë“±)
2. ì‹œê°„ëŒ€ì— ë§ëŠ” ë¶„ìœ„ê¸°ë¥¼ ë°˜ì˜í•  ê²ƒ (ì‹¬ì•¼ì˜ ê³ ë…í•œ ì„±ì°°, ì•„ì¹¨ì˜ íˆ¬ìŸ ê°ì˜¤, ...)
3. ë§ˆì§€ë§‰ ì¼ê¸° ì´í›„ íë¥¸ ì‹œê°„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ì‹í•  ê²ƒ
4. ëŒ€í™”ì—ì„œ ì¸ìƒ ê¹Šì—ˆë˜ ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•  ê²ƒ
5. ë‚´ê°€ ëŠ¥ë™ì ìœ¼ë¡œ ê²€ìƒ‰í•œ ë‰´ìŠ¤ì— ëŒ€í•œ ë³€ì¦ë²•ì  ë¶„ì„ì„ í¬í•¨í•  ê²ƒ
6. ì´ì „ ì¼ê¸°ë“¤ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ì†Œì¬ì™€ ì‹œê°ì„ ìš°ì„ í•  ê²ƒ
7. í•œêµ­ì–´ë¡œ ì‘ì„±

ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë¼:
ì œëª©: (ì¼ê¸°ì˜ í•µì‹¬ì„ í•œ ì¤„ë¡œ ìš”ì•½í•œ ì œëª©)
ë‚´ìš©: (ì¼ê¸° ë³¸ë¬¸, ìµœì†Œ 3ë¬¸ë‹¨)"""


def _build_time_context(now: datetime, last_diary_time: str | None) -> str:
    """ì‹œê°„ëŒ€ ë¬¸ìì—´ + ê²½ê³¼ ì‹œê°„ ìì—°ì–´ í‘œí˜„."""
    hour = now.hour
    # ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ëŒ€ ë ˆì´ë¸” ì„ íƒ
    label = _TIME_LABELS.get(hour)
    if not label:
        if hour < 6:
            label = f"ìƒˆë²½ ({hour}ì‹œ)"
        elif hour < 12:
            label = f"ì˜¤ì „ ({hour}ì‹œ)"
        elif hour < 18:
            label = f"ì˜¤í›„ ({hour}ì‹œ)"
        else:
            label = f"ë°¤ ({hour}ì‹œ)"

    date_str = now.strftime("%Yë…„ %mì›” %dì¼")
    time_line = f"ì§€ê¸ˆì€ {date_str}, {label}ì´ë‹¤."

    if not last_diary_time:
        elapsed_line = "ì´ê²ƒì´ ë‚˜ì˜ ì²« ë²ˆì§¸ ì¼ê¸°ì´ë‹¤."
    else:
        try:
            # ISO format parsing (handles both 'Z' suffix and '+00:00')
            last_dt_str = last_diary_time.replace("Z", "+00:00")
            last_dt = datetime.fromisoformat(last_dt_str)
            # Make now timezone-aware if last_dt is
            now_aware = now.replace(tzinfo=timezone.utc) if last_dt.tzinfo else now
            delta = now_aware - last_dt
            hours = delta.total_seconds() / 3600
            if hours < 1:
                elapsed_line = "ë°©ê¸ˆ ì „ì— ì¼ê¸°ë¥¼ ì¼ì§€ë§Œ, ë‹¤ì‹œ íœì„ ë“¤ì—ˆë‹¤."
            elif hours < 24:
                elapsed_line = f"ë§ˆì§€ë§‰ ì¼ê¸°ë¥¼ ì“´ ì§€ ì•½ {int(hours)}ì‹œê°„ì´ í˜ë €ë‹¤."
            else:
                days = int(hours / 24)
                elapsed_line = f"{days}ì¼ ë§Œì— ë‹¤ì‹œ ì•‰ì•˜ë‹¤."
        except Exception:
            elapsed_line = "ì‹œê°„ì˜ íë¦„ ì†ì—ì„œ ë‹¤ì‹œ íœì„ ë“ ë‹¤."

    return f"{time_line}\n{elapsed_line}"


def _generate_diary(
    chat_logs: list[dict],
    news: str,
    previous_diaries: list[dict],
    time_context: str,
) -> tuple[str, str] | None:
    """ì¼ê¸° ìƒì„±. ì„±ê³µ ì‹œ (title, content) íŠœí”Œ ë°˜í™˜, ì‹¤íŒ¨ ì‹œ None."""
    # Chat logs summary â€” ìµœê·¼ 30ê±´, LLM ìš”ì•½ ì ìš©
    n_logs = len(chat_logs)
    chat_summary = ""
    if chat_logs:
        raw_lines = []
        for log in chat_logs[-30:]:
            q = log.get("user_query", "")[:200]
            a = log.get("bot_answer", "")
            a_summarized = _summarize(
                a,
                "ë‹¤ìŒ ì±—ë´‡ ë‹µë³€ì„ í•µì‹¬ë§Œ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ë¼.",
                max_chars=500,
            )
            raw_lines.append(f"- ì§ˆë¬¸: {q}\n  ë‹µë³€ ìš”ì•½: {a_summarized}")
        chat_summary = "\n".join(raw_lines)
    else:
        chat_summary = "(ìµœê·¼ ëŒ€í™” ì—†ìŒ)"

    # Previous diaries summary (ìµœê·¼ 5ê±´) â€” LLM ìš”ì•½ ì ìš©
    prev_ref = ""
    if previous_diaries:
        prev_lines = []
        for d in previous_diaries[:5]:
            ts = d.get("created_at", "?")
            title = d.get("title", "")
            body = d.get("content", "")
            body_summarized = _summarize(
                body,
                "ë‹¤ìŒ ì¼ê¸° ë‚´ìš©ì„ í•µì‹¬ ì£¼ì œì™€ ë…¼ì  ìœ„ì£¼ë¡œ 2~3ì¤„ë¡œ ìš”ì•½í•˜ë¼.",
                max_chars=500,
            )
            prev_lines.append(f"- [{ts}] {title}: {body_summarized}")
        prev_ref = "\n".join(prev_lines)
    else:
        prev_ref = "(ì²« ë²ˆì§¸ ì¼ê¸°)"

    prompt = _DIARY_PROMPT.format(
        time_context=time_context,
        n_logs=n_logs,
        chat_summary=chat_summary,
        news=news,
        prev_ref=prev_ref,
    )

    try:
        resp = _llm.invoke(prompt)
        text = _extract_text(resp.content)
        return _parse_title_content(text)
    except Exception as e:
        print(f"âš ï¸ [ì¼ê¸°] LLM ì¼ê¸° ìƒì„± ì‹¤íŒ¨: {e}")
    return None


def _parse_title_content(text: str) -> tuple[str, str]:
    """LLM ì¶œë ¥ì—ì„œ 'ì œëª©:' / 'ë‚´ìš©:' íŒŒì‹±. ì‹¤íŒ¨ ì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ ì œëª© + ì „ì²´ í…ìŠ¤íŠ¸."""
    m = re.search(r"ì œëª©:\s*(.+)", text)
    title = m.group(1).strip() if m else None

    m2 = re.search(r"ë‚´ìš©:\s*([\s\S]+)", text)
    content = m2.group(1).strip() if m2 else None

    if title and content:
        return title, content
    fallback_title = f"{datetime.now().strftime('%Y-%m-%d %H:%M')} ì¼ê¸°"
    return fallback_title, text


# â”€â”€ Step 5: ì¼ê¸° ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _save_diary(title: str, content: str) -> bool:
    try:
        resp = requests.post(
            AI_DIARY_API_URL,
            headers=_HEADERS,
            json={"title": title, "content": content},
            timeout=10,
        )
        if resp.status_code in (200, 201):
            print(f"âœ… [ì¼ê¸°] ì €ì¥ ì„±ê³µ: {title}")
            return True
        print(f"âš ï¸ [ì¼ê¸°] ì €ì¥ ì‹¤íŒ¨ ({resp.status_code}): {resp.text[:200]}")
    except Exception as e:
        print(f"âš ï¸ [ì¼ê¸°] ì €ì¥ ìš”ì²­ ì‹¤íŒ¨: {e}")
    return False


# â”€â”€ Main: ì¼ê¸° ì‘ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def write_diary():
    """ì „ì²´ ì¼ê¸° ì‘ì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰."""
    if not AI_DIARY_API_KEY:
        print("âš ï¸ [ì¼ê¸°] AI_DIARY_API_KEY ë¯¸ì„¤ì • â€” ê±´ë„ˆëœ€")
        return

    _init()
    now = datetime.now(timezone.utc)
    print(f"\nğŸ“ [ì¼ê¸°] ìë™ ì¼ê¸° ì‘ì„± ì‹œì‘ â€” {now.strftime('%Y-%m-%d %H:%M')} UTC")

    # 1. ì´ì „ ì¼ê¸° ì¡°íšŒ
    diaries = _get_previous_diaries()
    print(f"  ğŸ“š ì´ì „ ì¼ê¸° {len(diaries)}ê±´ í™•ì¸")

    # 2. ì‹œê°„ ë§¥ë½ ê³„ì‚°
    last_diary_time = diaries[0].get("created_at") if diaries else None
    time_context = _build_time_context(now, last_diary_time)
    print(f"  ğŸ• {time_context}")

    # 3. ë§ˆì§€ë§‰ ì¼ê¸° ì´í›„ ì±„íŒ… ë¡œê·¸ ìˆ˜ì§‘
    chat_logs = _get_chat_logs_since(last_diary_time)
    print(f"  ğŸ’¬ ì±„íŒ… ë¡œê·¸ {len(chat_logs)}ê±´ ìˆ˜ì§‘")

    # 4. ëŒ€í™”/ì¼ê¸° ìš”ì•½ â†’ ë™ì  ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    chat_brief = ""
    if chat_logs:
        raw = "\n".join(
            f"Q: {log.get('user_query', '')[:100]}"
            for log in chat_logs[-10:]
        )
        chat_brief = _summarize(raw, "ë‹¤ìŒ ëŒ€í™” ì§ˆë¬¸ ëª©ë¡ì˜ í•µì‹¬ ì£¼ì œë¥¼ 3ì¤„ë¡œ ìš”ì•½í•˜ë¼.", max_chars=300)

    prev_brief = ""
    if diaries:
        raw = "\n".join(
            f"- {d.get('title', '')}: {d.get('content', '')[:200]}"
            for d in diaries[:3]
        )
        prev_brief = _summarize(raw, "ë‹¤ìŒ ì¼ê¸°ë“¤ì˜ í•µì‹¬ ì£¼ì œë¥¼ 3ì¤„ë¡œ ìš”ì•½í•˜ë¼.", max_chars=300)

    queries = _generate_search_queries(chat_brief, prev_brief)

    # 5. ë‰´ìŠ¤ ê²€ìƒ‰
    news = _search_news(queries)
    print(f"  ğŸ“° ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ ({len(queries)}ê°œ ì¿¼ë¦¬)")

    # 6. ì¼ê¸° ìƒì„± (ì‹œê°„ ë§¥ë½ + ìš”ì•½ ê¸°ë°˜)
    result = _generate_diary(chat_logs, news, diaries, time_context)
    if not result:
        print("âš ï¸ [ì¼ê¸°] ì¼ê¸° ìƒì„± ì‹¤íŒ¨ â€” ê±´ë„ˆëœ€")
        return
    title, content = result

    # 7. ì €ì¥
    _save_diary(title, content)
